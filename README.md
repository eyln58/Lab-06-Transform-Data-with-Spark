# 🔄 Data Transformation with Apache Spark in Azure Synapse

## Overview

This project demonstrates how to transform structured data using **Apache Spark notebooks** in **Azure Synapse Analytics**. As part of a data engineering training lab, I explored the integration between Azure Synapse Studio, Spark Pools, and Data Lake Storage to process and prepare data for analytics.

## 🧩 What I Did

- **Connected Synapse to Azure Data Lake Storage Gen2**
  - Verified access to structured `.csv` data files across multiple years

- **Imported and ran a Spark notebook (`Spark Transform.ipynb`)**
  - The notebook was executed using the pre-provisioned Spark pool in Synapse
  - Used PySpark to manipulate, clean, and prepare data for downstream analysis

- **Reviewed column headers and schema**
  - Ensured that transformations were applied to correctly typed data
  - Focused on maintaining data integrity during manipulation

## ✅ Key Learnings

- How to manage and run Spark notebooks in **Azure Synapse Studio**
- How to use **PySpark** for scalable, cloud-native data transformations
- Gained confidence with **Data Lake + Spark** integration in a real-world environment

## 📁 Technologies Used

- Azure Synapse Analytics  
- Apache Spark & PySpark  
- Azure Data Lake Storage Gen2  
- Jupyter (Synapse Notebooks)

---

📎 **Connect with me at Linkedin**: [https://www.linkedin.com/in/eyilan/]

